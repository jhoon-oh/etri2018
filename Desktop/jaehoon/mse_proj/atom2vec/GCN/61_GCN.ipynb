{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(graph_atoms):\n",
    "    N = len(graph_atoms)\n",
    "    for i in range(N):\n",
    "        graph_atoms[i] = atom2vec[graph_atoms[i]]\n",
    "    return np.array(graph_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(crd1, crd2):\n",
    "    crd1 = np.array(crd1)\n",
    "    crd2 = np.array(crd2)\n",
    "    return np.linalg.norm(crd1-crd2)\n",
    "\n",
    "def get_adj(graph_crd):\n",
    "    N = len(graph_crd)\n",
    "    adj = np.ones([N,N])*0.5\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i!=j:\n",
    "                adj[i][j]=1/get_dist(graph_crd[i],graph_crd[j])\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms_loc_data = pd.read_csv('O_atom_location.csv')\n",
    "atoms_loc_data['coord'] = [tuple(row[col] for col in ['x', 'y', 'z']) for _, row in atoms_loc_data.iterrows()]\n",
    "atoms_loc_data = atoms_loc_data.drop('x', axis=1)\n",
    "atoms_loc_data = atoms_loc_data.drop('y', axis=1)\n",
    "atoms_loc_data = atoms_loc_data.drop('z', axis=1)\n",
    "atom2vec = pd.read_csv('atom2vec_SVD20.csv', index_col=0).T\n",
    "energy_data = list(pd.read_csv('mat_energy.csv')['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = []\n",
    "for i in range(max(set(atoms_loc_data['num']))):\n",
    "    nodes = get_feature(list(atoms_loc_data[atoms_loc_data['num']==i+1]['atom']))\n",
    "    adj = get_adj(list(atoms_loc_data[atoms_loc_data['num']==i+1]['coord']))\n",
    "    energy = energy_data[i]\n",
    "    if energy > 0:\n",
    "        graph_data.append([nodes, adj, energy])\n",
    "##### graph_data[idx][0] => N*D feature matrix\n",
    "##### graph_data[idx][1] => N*N adjacency matrix\n",
    "##### graph_data[idx][2] => 1 energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = []\n",
    "for i in range(int(len(set(atoms_loc_data['num']))/4)):\n",
    "    min_idx = np.argmin(energy_data[i*4:(i+1)*4])\n",
    "    idx = 4*i + min_idx\n",
    "    nodes = get_feature(list(atoms_loc_data[atoms_loc_data['num']==idx+1]['atom']))\n",
    "    adj = get_adj(list(atoms_loc_data[atoms_loc_data['num']==idx+1]['coord']))\n",
    "    energy = energy_data[idx]\n",
    "    if energy > 0:\n",
    "        graph_data.append([nodes, adj, energy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 246 62\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "num_of_data = len(graph_data)\n",
    "num_of_train = int(len(graph_data)*0.8)\n",
    "num_of_test = len(graph_data)-num_of_train\n",
    "print (num_of_data, num_of_train, num_of_test)\n",
    "train_data, test_data = random_split(graph_data, [num_of_train, num_of_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grpah NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features, init):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(batch_size, in_features, out_features))\n",
    "        #self.bias = nn.Parameter(torch.FloatTensor(batch_size, out_features))\n",
    "\n",
    "        if init == 'uniform':\n",
    "            print(\"| Uniform Initialization\")\n",
    "            self.reset_parameters_uniform()\n",
    "        elif init == 'xavier':\n",
    "            print(\"| Xavier Initialization\")\n",
    "            self.reset_parameters_xavier()\n",
    "        elif init == 'kaiming':\n",
    "            print(\"| Kaiming Initialization\")\n",
    "            self.reset_parameters_kaiming()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def reset_parameters_uniform(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        #self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def reset_parameters_xavier(self):\n",
    "        nn.init.xavier_normal_(self.weight.data, gain=0.02) # Implement Xavier Uniform\n",
    "        #nn.init.constant_(self.bias.data, 0.0)\n",
    "\n",
    "    def reset_parameters_kaiming(self):\n",
    "        nn.init.kaiming_normal_(self.weight.data, a=0, mode='fan_in')\n",
    "        #nn.init.constant_(self.bias.data, 0.0)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        output = torch.bmm(adj, torch.bmm(input, self.weight))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nclass, init):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, 20, init=init)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.gc2 = GraphConvolution(20, 20, init=init)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.gc3 = GraphConvolution(20, nclass, init=init)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x1 = self.act1(self.gc1(x, adj))+x\n",
    "        x2 = self.act2(self.gc2(x1, adj))+x+x1\n",
    "        x3 = self.gc3(x2, adj)\n",
    "        output = torch.mean(x3, dim=1).view(batch_size)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "num_epochs = 10000\n",
    "batch_size = int(num_of_data*0.1)+1\n",
    "learning_rate = 1e-4\n",
    "\n",
    "criterion = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "def fit(model,train_loader,criterion,learning_rate,num_epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=1e-6)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=int(num_epochs/2), gamma=0.1)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss=0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            features = data[0].type(torch.FloatTensor).cuda(0)\n",
    "            adj = data[1].type(torch.FloatTensor).cuda(0)\n",
    "            energy = data[2].type(torch.FloatTensor).cuda(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(features, adj)\n",
    "            \n",
    "            loss = criterion(output, energy)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            features = features.cpu()\n",
    "            adj = adj.cpu()\n",
    "            energy = energy.cpu()\n",
    "\n",
    "        if epoch==0 or (epoch+1)%1000 == 0:\n",
    "            print (\"Epoch [%d/%d], train loss avg : %.4f\" % (epoch+1, num_epochs, epoch_loss/len(train_loader)))\n",
    "            curr_lr = optimizer.param_groups[0]['lr']\n",
    "            print('Learning rate : {}\\n'.format(curr_lr))\n",
    "        scheduler.step()\n",
    "        # file_name = './model/'+model_name+'/epoch{}.pth'.format(epoch+1)\n",
    "        # torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Uniform Initialization\n",
      "| Uniform Initialization\n",
      "| Uniform Initialization\n",
      "Epoch [1/10000], train loss avg : 0.9313\n",
      "Learning rate : 0.0001\n",
      "\n",
      "Epoch [1000/10000], train loss avg : 0.0324\n",
      "Learning rate : 0.0001\n",
      "\n",
      "Epoch [2000/10000], train loss avg : 0.0225\n",
      "Learning rate : 0.0001\n",
      "\n",
      "Epoch [3000/10000], train loss avg : 0.0170\n",
      "Learning rate : 0.0001\n",
      "\n",
      "Epoch [4000/10000], train loss avg : 0.0150\n",
      "Learning rate : 0.0001\n",
      "\n",
      "Epoch [5000/10000], train loss avg : 0.0118\n",
      "Learning rate : 0.0001\n",
      "\n",
      "Epoch [6000/10000], train loss avg : 0.0096\n",
      "Learning rate : 1e-05\n",
      "\n",
      "Epoch [7000/10000], train loss avg : 0.0106\n",
      "Learning rate : 1e-05\n",
      "\n",
      "Epoch [8000/10000], train loss avg : 0.0111\n",
      "Learning rate : 1e-05\n",
      "\n",
      "Epoch [9000/10000], train loss avg : 0.0110\n",
      "Learning rate : 1e-05\n",
      "\n",
      "Epoch [10000/10000], train loss avg : 0.0105\n",
      "Learning rate : 1e-05\n",
      "\n",
      "--- 69.21545910835266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model = GCN(20, 1, 'uniform').cuda(0)\n",
    "start_time = time.time()\n",
    "\n",
    "fit(model, train_loader, criterion, learning_rate, num_epochs)\n",
    "print (\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "def eval(model,test_loader):\n",
    "    model.eval()\n",
    "    pred_all = []\n",
    "    real_all = []\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "        features = data[0].type(torch.FloatTensor).cuda(0)\n",
    "        adj = data[1].type(torch.FloatTensor).cuda(0)\n",
    "        energy = data[2].type(torch.FloatTensor).cuda(0)\n",
    "        real_all += list(energy.cpu().detach().numpy())\n",
    "        \n",
    "        pred_energy = model(features, adj)\n",
    "        pred_energy = list(pred_energy.cpu().detach().numpy())\n",
    "        pred_all += pred_energy\n",
    "\n",
    "    real_all = np.array(real_all)\n",
    "    pred_all = np.array(pred_all)\n",
    "    l1_loss = np.abs(real_all-pred_all).mean(axis=0)\n",
    "    print (l1_loss)\n",
    "    return real_all, pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.186201\n"
     ]
    }
   ],
   "source": [
    "real_all, pred_all = eval(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.1391143394322574, 2.8490436901958169)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAD8CAYAAACcoKqNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAHCtJREFUeJzt3X2QVPWd7/H3t+cBZUHRMArqjBhBUbwbIYheEw34cFfZ7NUL/KGrpoLJtUDiNZVNqm7tH6Yqf23V1rUqRpDiRt1yY8VUBda1NnitBHzATUmCMBpkUIloAHEAUR4EGab7e//obuzpOf00c/r0Od2fV9WUQ/dh5jft9Iff+f6ezN0RkdaWanQDRKTxFAQioiAQEQWBiKAgEBEUBCKCgkBEUBCICAoCEQHaG/WNJ06c6FOmTGnUtxdpavv27eOTTz7h6NGjB9y9q9L1DQuCKVOmsGnTpkZ9e5Gm5O4sX76c1atXs3DhQh544IEPqvl7ujUQaRLFIbBs2bKq/66CQKQJBIWAmVX99xUEIgk32hAABYFIooURAqAgEEmssEIAFAQiiRRmCICCQCRxwg4BUBCIJEo9QgAUBCKJUa8QAAWBSCLUMwRAQSASe/UOAVAQiMRaFCEACgKR2IoqBKCBqw9FZLh0xnnp7X1s3XOI97dsYMvaNSyqcwiAgkAkNtIZ557HN9K761OODQxi6bPpvv5+lixdUNcQAN0aiMTGS2/vy4VAGjC8rZMDPo6X39lf9++tIBCJia17DnFsYHDIY8cH0mz78HDdv7duDURiwN15f8sGLH023tZ56vHTO9uYPnk86/r6eevDw8w47wzmXnoObalwbxUUBCINlh8d2LJ2Dd3X388Bb+P4QJrTO9u4snsCT7y6kzd2Hxry2L9+5+pQw0BBINJAhUOEixYuZMnSBbz8zn62fXiYy887g0zGefBXvbm6ARwbSNO761NeensfN152bmjtqFgjMLNuM3vRzLaZ2Vtm9mDANXPN7JCZ9eY+HgqthSJNKmieQHtbihsvO5cHbpzGjZedS99HRzieC4G8etQNqukRDAL/4O6bzWw88LqZ/dbdtxVdt8Hdvxlq60SaVLWThWacdwand7ad6hFAtm5w+XlnhNqeij0Cd9/r7ptznx8B+oDzQ22FSAupZcbg3EvP4cruCYztbMOAsbkawdxLzwm1TTXVCMxsCjAT2Bjw9LVm9iawB/ihu7816taJNJlapw23pYx//c7VvPT2vlN1g4aOGpjZOGA18H13L75B2Qz0uPtRM5sPPAtMC/ga9wH3AfT09Iy40SJJNNK1A20p48bLzg21OFisqglFZtZBNgSedvc1xc+7+2F3P5r7fC3QYWYTA65b5e6z3X12V1fFU5hEmkaUC4hGoppRAwMeB/rc/eES10zKXYeZzcl93Y/DbKhIUsU9BKC6W4OvAfcAfzKz3txj/wj0ALj7SmARsNTMBoHjwB3u7nVor0iiJCEEoIogcPdXgbItd/dHgUfDapRIM0hKCIAWHYnURZJCADTFWKSk/CYhtS72SVoIgIJAJFDhJiG1LPZJYgiAbg1EAhVuEuIMXexTSlJDABQE0mTSGWddXz+PrHuXdX39pDMjG7x668PDNS32SXIIgG4NpImMtDsfpJbFPkkPAVCPQJrISLrzpVS72CfKEAirtxNEPQJpGuW687XO069msU/UIRBWbyeIegTSNPLd+UKjWbufX+yT3ySkVAj8jwULmX7DIn62fkfo/1LnhdnbCaIegTSNfHe++F/NsNfuF4fAa6fNZuUzvXXdUzDM3k4QBYE0jSjW7hffDky/YRErn6n/noL13qlItwbSVMp150crqCawbW80ewrWe6ci9QhEqlCqMBjVnoL17u0oCEQqKDc6EFVdAuq7U5GCQKSMSkOEUe0pWG8KApESqp0nEMWegvWmYqFIgGaYNlwLBYFIkVYLAVAQiAzRiiEAqhG0nJHuutMKWjUEQEHQUuq9cCXJWjkEQLcGLaUeC1fquTQ2Kq0eAqAeQUsJe+FKknsY+VukrXsO8f6WDWxZu4ZFLRoCoCBoKWFPhy3sYUD9FtyErTDAjg0MYumz6b7+fpYsXdCSIQC6NWgpYS9cqXVfv7gYGmCGt3VywMfx8jv7G920hlGPoIWEPR02qgU3Ydu65xDHBgYpPMArzLX9SaQgaDFhToeNcsFNWNyd97dswNJn422dpx5PQoDVU8UgMLNu4CngXMCBVe7+06JrDPgpMB84Bnzb3TeH31yJk6QtuMmPDmxZu4bu6+/ngLclJsDqrZoewSDwD+6+2czGA6+b2W/dfVvBNbcC03IfVwOP5f4rTS4pC24KhwgXLVzIkqULePmd/YkIsChUcxryXmBv7vMjZtYHnA8UBsFtwFO5o9BfM7MJZjY593dFGqrUPIEkBFhUaho1MLMpwExgY9FT5wO7Cv68O/eYSENpslB1qg4CMxsHrAa+7+4jGh8ys/vMbJOZbdq/v3WHaiQa+RD49eo1XDn/btLT/xvrt+9L5OzHeqtq1MDMOsiGwNPuvibgkj1Ad8GfL8g9NoS7rwJWAcyePVv/N6RuCkMgc/39vHBkHMd/926iZj9GqWKPIDci8DjQ5+4Pl7jsOeBblnUNcEj1AWmUwtuBmfPv4oCPq9vBIM2imluDrwH3ADeYWW/uY76ZLTGzJblr1gLvATuA/wvcX5/mipRXXBOYMvO6RM5+jFo1owavUjgFK/gaB5aF1SiRckrtqRBUGFy/fV8iZz9GTTMLJVFKrXh86t45rHxsxbDRgSTOfmwEBYHEUql/9UutePzRw0/SuzZ4iHDxtVP4zZ+yJau//evJ3DA93BOQmoGCQGKn3D4HQSsejw0M8mLvDr5bFAJBX2ffkRPcMF2TiIppGbLETrmdlIKOPrf0SeZdOXVYT6DeR4k3EwWBxE65fQ4K91QAx9IDdI9N888/WDxsxmBS90toBAWBxELh3oeD6QyndQz91cxX+ttSxlP3zuFvxu9hwq7/5PZzDrL+oQW0tw3/VQ7qPWjEIJhqBNJwQffyne3ZN/bnJzNDKv3uzsrHVtC7dnWuJnBvybUDGjGonoJAGi5oJGBsZxv/87ov09GWOrVMOGXUtIAoafslNJKCQBqu1L18R1uKB26cBox8FWFS9ktoNAWBNFylvQ9LhYBObQqPgkAarty9fLkQSOqZCnGkIJCGK3UvX64mkNQzFeJKQSCxUHwvX6kmEPapTa1O8wgkdqopDGqOQLgUBBIr1Y4OhH1qU6vTrYFEopoKfy1DhJojEC4FgdRdNRX+oBDIOLy0vb9keGiOQHgUBFJ3lSr8pULg7p+/xua/fMqJwQxj2lPM6pnAL757jf7VrwPVCKTuylX4S90OrO/rZ+POg5wYzABwYjDDxp0HWd/X34gfoempRyBAtvu+vq+/Ljv5lJo5eNnk8SVrAr/5016Kjx/IePbxm2dMGnWbZCgFgZDOOHf//DU27jx46s333Bsfcs2XvxTKTL1SMwe3rfs1/7ZGJxDFgYJAeOntfWz+y6dD/gXOOLz+wSehzNQrrvBfNnl8xRD427+ezHNvfDikTSnLPi7hU41AeOvDw6fuxQudGMyEtptPvsL/vRumsn195Z7ANy45h0vOHX+qNzKmPcXVF30JHB5Z9y7r+vp1dFmI1CMQZpx3BmPaU8PCYEx7KtSZetXOE0hnnG8/+Qc++Pgz0hmno824aOJf4Z7hwV/1apFRHahHIMy99Bxm9Uyg8P2UMvjqhWeFNlOvlslC+eHG4yezwXQy7ew88Blbdh3SRqR1oh6B0JYyfvHda+o2alDrpiJBw41Bty5aZBQeBYEA2TC4ecak0IfmRrKzUNBw45jcHoaFgaBFRuHRrYHUzUi3FwtaUPTVC89iVo8WGdVLxR6BmT0BfBPY5+5XBDw/F/h3YGfuoTXu/pMwGynJM9IQgNILigAtMqoTyx5kXOYCs+uBo8BTZYLgh+7+zVq+8ezZs33Tpk21/BVJiNGEgITLzF5399mVrqt4a+DurwAHQ2mVND2FQDKFVSO41szeNLPnzWxGSF9TEkYhkFxhjBpsBnrc/aiZzQeeBaYFXWhm9wH3AfT09ITwrSUuFALJNuoegbsfdvejuc/XAh1mNrHEtavcfba7z+7q6hrtt5aYUAgk36iDwMwmWe7/upnNyX3Nj0f7dSUZFALNoZrhw18Cc4GJZrYb+DHQAeDuK4FFwFIzGwSOA3d4paEIaQoKgeZRMQjc/c4Kzz8KPBpaiyQRFALNRTMLpWYKgeajtQYJEZcDP2tZShyH9kp1FAQJEJcDP2sJgTi0V6qnW4MEKNwOvFFr8Ueyn4D2DkgOBUEClNsOPAph7CcQZXuldgqCBGjkgZ+1hEA646zr6+e9/UfpbB/6q6W9A+JNNYIEKLUdeL3X4rs7P3t0OU+v38LUm7/DJfNu4nfb+un76MiwAmBxXcAsu91ZxrV3QBJUXIZcL1qGXJt8FT6qtfj5EFixLUV6QjeDniLfESh8c+cLgOv6+nngl1uG7Sp06xWT+LuvnKdRgwapdhmyegQJEeWBn/nbgafXbyE9/XZOeir3+BfXFJ9fGFQXGBjMcHHXOO0pmACqEcgQhTWBqVfNY9BL/4oUFgAbWceQ0VMQyCnFhcHFt9807M1dqPCNHrTPoOoCyaFbgxYUNOsvZQQeTV5YpAyqEeTf6KX2GVRdIBlULGwxpWb9XfP5psBjyAqLlNMnjweH7R8d0Rs9IVQslECFs/4gW/T743v7+fP2LdwTME8gqEipY8mbj4KgxQRV909mYOpV81i27C6tImxRKha2mKDqfkcKFt9+k0KghSkIWky+ut9hGfAMHZbhqi93MW+6xvpbmW4NWkzK4JrPN/Hn7VuYetU8Ft9+E/NCOuxUkktB0ELy8wT+bc3qXGFQNQHJ0q1Bi9D2YlKOegRNqHjC0Dcu6WLlYysUAlKSgqDJBE0YmmhHSb2yhkUKASlBtwZNJmibsF3H2pg5/y6FgJSkIGgyQROGvK0D755FRsfOSAkKgiYTNGEIjOe3fsQ9j28krTSQAAqCJvONS7qYaEchfRL44k1/YjCjnYSlJAVBE3F3Vj62gtQrK5g+7nNgaD1AOwlLKRWDwMyeMLN9Zra1xPNmZo+Y2Q4ze9PMZoXfTKmkcJ7AggUL4Mzzhl2jHYOklGp6BP8C3FLm+VuBabmP+4DHRt8sqUXxZKHLb1zEBx9/Nuy6C88eqx2DJFDFIHD3V4CDZS65DXjKs14DJpjZ5LAaKOUFzRjctvcIn5/MDLv2knPHsfzFHazr61fRUIYIY0LR+cCugj/vzj22N4SvnUhRHQBaatpwfuSgcGvxlMH/e6ufgTf26ixCGSbSmYVmdh/Z2wd6enqi/NaRieoA0HJrB4oPROlsT3EyneHEYLaXULwVuUgYowZ7gO6CP1+Qe2wYd1/l7rPdfXZXV1cI3zp+ojgAtNICovxGoj+7cyY/uPkSbr1i0rDJRBpBkEJhBMFzwLdyowfXAIfcvWVvC2o5ADR/VuAj696t+r692lWE+b0GH7hxGn/3lfMYqzMHpIyKtwZm9ktgLjDRzHYDPwY6ANx9JbAWmA/sAI4Bi+vV2CQIuj8PetON5BZipEuJG3V2oiRHxSBw9zsrPO/AstBalHDVvumCdhMud98+mv0EdOaAVKJlyCGr9k1X7haiOAjC2FQkyrMTJXkUBHVQzZuu2luIkYRAVMOX0jwUBA1SzS3ESEMgiuFLaS4KggapdAsx0tuBWmsPIqAgqEq9utqlbiFGUxOopfYgkqcgqCDqrvZoC4PV1h5ECmk/ggqimCmYVxwCS5bez/rt+2qacJSvPYztbMMYfny5SBD1CCqIqqsdFALfeuIPNfdENGdARkJBUEEUXe2g24H120de9NOcAamVbg3KSGecTMb50l91MqY9VZeudqmaQC1rFkRGSz2CEgqLhMcG0oxpT3HB2afz0Dcv54aQDg0tVxhU0U+ipB5BCcXj8ScGM3x8dICUWd1DAFT0k2i1dI8gaH4AZEPg8Vd31q1IWM0QoYp+EqWWDYKg+QFfueBMzGxIT6BQGF3zwXSGHz38JC/27mHe/LtZsnTxsBAoDqj7501VAEhdtWwQBE3F3fyXTwFObemVZxDKGv7BdIYbfrKGXcfOxru/xgtH2ul/4g9DhgS1VkAaoWVrBEFV+RODmWEhAHDtxV/iZ3fOHNWb0d350cNPsutYG97WCVjg5KQoJzCJ5LVsEASdETimPcWY9qEvydjONu79+kXceNnIRwryNYEXe3fgbR1DniseEtSwoTRCywZBUFV+Vs8EvnrhWaFW6gsLg/OunMrYzqF3Y8V1h6CA0rCh1FvL1ghKVeWB0Cr1w6cNL6Y/YNpwYdBof0FpBMtuORi92bNn+6ZNm8pek+SddkoNEeZ/pq17DpPOZEiljP9y/plDfrb8NRo2lNEys9fdfXal62LbI0hS9bw4sL5xSRcrH1sROE+gLWXMvfQcHn9157Cf7V8Wz2HDu/s1bCiRi20QJGWnnXxgvf7BJ5wYzDCmPcU5qc9o27CGRSUmC5X62f77o6/yl4PHYh980nxiWyxMSvV8/fZ+Xnvv41PDjicGM+w6MYYrb72r5KYipX62P+8/qmFDaYjYBkFSque/eXPvsOPEMIOeWSV3Fgr62drbjJPpoV8ojsEnzSm2QZDsRTflu/JBP9vUrnGc3jH0f0ccg0+aU2xrBElZdHPLjEk827uH4jf/rVdMKvl3gn6266Z18e0nyw8titRLbIMA4rvTzhdDgIf4/Wt/AD8zezuQY0CqwoajQT9bEoJPmlOsgyCOhm5YMgiZ8VD0ZnVg+0dHuHlG6V5BkFqDL8nzLCReqgoCM7sF+CnQBvzc3f+p6Pm5wL8DO3MPrXH3n4TYztgYOvRnkBr+Eo5pTzF90vi6tiNJ8ywk/ioWC82sDVgO3ApcDtxpZpcHXLrB3a/MfTRlCABs3XMo2xMoUvjWO5nO8OTv369q+/GR0ipFCVM1owZzgB3u/p67DwDPALfVt1nx5O68v2UDlj455PHONqO97YsoyDh1f1MmZZ6FJEM1QXA+sKvgz7tzjxW71szeNLPnzWxG0Bcys/vMbJOZbdq/f/8Imts4+bUDW9Y+TffY9JChv3PPOI3BiOcAJGWehSRDWMXCzUCPux81s/nAs8C04ovcfRWwCrKLjkL63nVXuIBo0cKFLFm6gJff2X+qup9x58FneiPdcVirFCVM1QTBHqC74M8X5B47xd0PF3y+1sxWmNlEdz8QTjMbp9QqwsLqfjrjkb8pkzLPQpKhmiD4IzDNzC4iGwB3AH9feIGZTQL63d3NbA7ZW46Pw25s1Ko9kLRRb8q4zrOQ5KkYBO4+aGbfA14gO3z4hLu/ZWZLcs+vBBYBS81sEDgO3OGN2uggJLWeSqw3pSRZrDcmaZTRHk0uEhfVbkwS20VHjaIQkFbUElOMq52KqxCQVtWUQVD4xr9s8nieeHUnb+w+VHYqrkJAWlnTBUHxHPzO9hQn05lTm4cEbXmmEJBW13Q1guI5+CcGM8N2EDo+kGbrnuzUB4WASBMGQdAc/GIOPL91L4PpjEJAhCa8NcjPwS+c7mtk3/yFPvj4M3708JP0rlUIiDRdjyBoP8ALzjp92HXHT6Z5sXdH6CGQzjjr+vp5ZN27rOvrr+tSZJGwJL5HEDQ0WDzdN5NxHvzV0EVBlj7JvCunsmzZvaGEQDrjrO/r5yf/sY19R04wMJjRZiGSGIkOgnK79JRaFHRsYBBLn6R7bJp//sHi0EKg8JCTvLgeyiJSLNG3BtXu0tOWMp66dw5/M34PE3b9J7efc5D1Dy2gvS2cHz/fjsIQyNNmIZIEiQ6CanfpcXdWPraC3rW/4Lv/9Xwe/uG9oYVAqXbkabMQSYJEB0E1u/REMU8gqB2Q3cRUm4VIEiQ6CCqdhhTVZKHCdkA2ALrPPp1H/36mCoWSCIlfhpwfNSjeECTqGYOl2iHSSNUuQ05EENR6kIemDYtkVRsEsR8+rPUgD3fnZ48u5+n1W5h683eYfsNNZBzalAMiJcW+RlDLQR75EFixLcXB6bfz+8Nn8b+e6eWexzdqhp9IGbEPglqGCJcvz/YE0hO6OekpnQAkUqXYB0GtQ4RTr5rHoA/9sTSpR6S82AdBrUOEi2+/idM6hv5Yp3WkNKlHpIzYFwvLnRkQNDrw+ckMxQMEne0prpvW1ZgfQCQBYh8EEHxmQD4Efr16DTPn3016+nX8bls//+e373BsYOic/4HBDBve3a+FPyIlJCIIihWGQOb6+3nhyDiO/+5dOttTDAQt/DmZYduHhxUEIiXEvkZQrPB2YOb8uzjg44bsTxg0SNjRZqoRiJSRqCAorglMmXldxf0JAS7uGqeFPyJlJCYIggqDV5x/5rChxZRlF/0Y2Z7AZZPG89z3vq55/yJlVFUjMLNbgJ+SPQT15+7+T0XPW+75+cAx4NvuvjmsRpZaO5AfWiycfvyVC87k3q9fxPa9R7T4R6RKFYPAzNqA5cDNwG7gj2b2nLtvK7jsVmBa7uNq4LHcf0et3AKickOLN18+KYxvL9ISqukRzAF2uPt7AGb2DHAbUBgEtwFP5Y5Cf83MJpjZZHffO5rGVbOKUMeRi4xeNTWC84FdBX/enXus1mtqoqXEItGJtFhoZveZ2SYz27R///6S1ykERKJVTRDsAboL/nxB7rFar8HdV7n7bHef3dUVPOVXISASvWqC4I/ANDO7yMw6gTuA54queQ74lmVdAxwaSX1AISDSGBWLhe4+aGbfA14gO3z4hLu/ZWZLcs+vBNaSHTrcQXb4cHGtDVEIiDROVfMI3H0t2Td74WMrCz53YNlIG6EQEGmshs8sVAiINF5Dg0AhIBIPDQ0ChYBIPDTsXIOenh6/+OKLFQIidVTtuQYN6xF88sknCgGRmGhYj8DM9gMfVHHpROBAnZtTq7i1Se2pLG5tiqo9F7p7xQ07GxYE1TKzTdV0baIUtzapPZXFrU1xa0/Dhw9FpPEUBCKSiCBY1egGBIhbm9SeyuLWpli1J/Y1AhGpvyT0CESkzmITBGZ2i5m9bWY7zOx/BzxvZvZI7vk3zWxWg9sz18wOmVlv7uOhOrfnCTPbZ2ZbSzwf6etTZZuifo26zexFM9tmZm+Z2YMB10T2OlXZnkhfo5LcveEfZJc3/xn4MtAJvAFcXnTNfOB5wIBrgI0Nbs9c4D8ifI2uB2YBW0s8H9nrU0Obon6NJgOzcp+PB95p8O9RNe2J9DUq9RGXHsGpDVLdfQDIb5Ba6NQGqe7+GjDBzCY3sD2RcvdXgINlLony9am2TZFy972e20bf3Y8AfQzfOzOy16nK9sRCXIKgIRukjrI9ANfmupfPm9mMOrWlWlG+PrVoyGtkZlOAmcDGoqca8jqVaQ/E4PcokYegxsRmoMfdj5rZfOBZsuc6yBca8hqZ2ThgNfB9dz9c7+83yvbE4vcoLj2C0DZIjao97n7Y3Y/mPl8LdJjZxDq1pxpRvj5VacRrZGYdZN90T7v7moBLIn2dKrUnLr9HcQmCyDZIDas9ZjbJcssmzWwO2dfy4zq1pxpRvj5Vifo1yn2vx4E+d3+4xGWRvU7VtCcuv0exuDXwiDZIDbk9i4ClZjYIHAfu8FwZuB7M7JdkK8wTzWw38GOgo6A9kb0+NbQp0tcI+BpwD/AnM+vNPfaPQE9Bm6J8nappT9SvUSDNLBSR2NwaiEgDKQhEREEgIgoCEUFBICIoCEQEBYGIoCAQEeD/Ax1CWo2kLzbUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f21f7d82ef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(real_all, pred_all, s=25)\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
