{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymatgen import Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ru', 'Al', 'Mg', 'Be', 'Rh', 'Pd', 'Cd', 'V', 'Au', 'Ag', 'Mo', 'Os', 'Hf', 'Ta', 'Ni', 'Fe', 'Tl', 'Co', 'Pb', 'Mn', 'W', 'Ti', 'Cu', 'Cr', 'Ir', 'Pt', 'Nb', 'Ba', 'Zn', 'Re', 'Na', 'Lu', 'Y', 'Li', 'Zr', 'Rb', 'Sc', 'Tc', 'K']\n"
     ]
    }
   ],
   "source": [
    "energy_data = pd.read_csv('mat_energy.csv')\n",
    "our_atoms = []\n",
    "for i in range(len(energy_data)):\n",
    "    tmp = energy_data['material'][i].split('/')[0]\n",
    "    our_atoms.append(tmp.split('3')[0])\n",
    "    our_atoms.append(tmp.split('3')[1])\n",
    "our_atoms = list(set(our_atoms))\n",
    "print (our_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 11, 12, 13, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 56, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82]\n"
     ]
    }
   ],
   "source": [
    "our_atoms_no = []\n",
    "for i in range(len(our_atoms)):\n",
    "    our_atoms_no.append(Element(our_atoms[i]).data['Atomic no'])\n",
    "#print (our_atoms_no)\n",
    "print (sorted(our_atoms_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atomic mass': 101.07,\n",
       " 'Atomic no': 44,\n",
       " 'Atomic orbitals': {'1s': -782.918621,\n",
       "  '2p': -102.333649,\n",
       "  '2s': -110.536054,\n",
       "  '3d': -10.195668,\n",
       "  '3p': -16.145217,\n",
       "  '3s': -19.366692,\n",
       "  '4d': -0.210375,\n",
       "  '4p': -1.667549,\n",
       "  '4s': -2.628363,\n",
       "  '5s': -0.152834},\n",
       " 'Atomic radius': 1.3,\n",
       " 'Atomic radius calculated': 1.78,\n",
       " 'Boiling point': '4423 K',\n",
       " 'Brinell hardness': '2160 MN m<sup>-2</sup>',\n",
       " 'Bulk modulus': '220 GPa',\n",
       " 'Coefficient of linear thermal expansion': '6.4 x10<sup>-6</sup>K<sup>-1</sup>',\n",
       " 'Common oxidation states': [3, 4],\n",
       " 'Critical temperature': 'no data K',\n",
       " 'Density of solid': '12370 kg m<sup>-3</sup>',\n",
       " 'Electrical resistivity': '7.1 10<sup>-8</sup> &Omega; m',\n",
       " 'Electronic structure': '[Kr].4d<sup>7</sup>.5s<sup>1</sup>',\n",
       " 'ICSD oxidation states': [2, 3, 4, 5, 6],\n",
       " 'Ionic radii': {'3': 0.82, '4': 0.76, '5': 0.705, '7': 0.52, '8': 0.5},\n",
       " 'Liquid range': '1816 K',\n",
       " 'Melting point': '2607 K',\n",
       " 'Mendeleev no': 62,\n",
       " 'Mineral hardness': '6.5',\n",
       " 'Molar volume': '8.17 cm<sup>3</sup>',\n",
       " 'Name': 'Ruthenium',\n",
       " 'Oxidation states': [-2, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       " 'Poissons ratio': '0.30',\n",
       " 'Reflectivity': 'no data %',\n",
       " 'Refractive index': 'no data',\n",
       " 'Rigidity modulus': '173 GPa',\n",
       " 'Shannon radii': {'3': {'VI': {'': {'crystal_radius': 0.82,\n",
       "     'ionic_radius': 0.68}}},\n",
       "  '4': {'VI': {'': {'crystal_radius': 0.76, 'ionic_radius': 0.62}}},\n",
       "  '5': {'VI': {'': {'crystal_radius': 0.705, 'ionic_radius': 0.565}}},\n",
       "  '7': {'IV': {'': {'crystal_radius': 0.52, 'ionic_radius': 0.38}}},\n",
       "  '8': {'IV': {'': {'crystal_radius': 0.5, 'ionic_radius': 0.36}}}},\n",
       " 'Superconduction temperature': '0.49 K',\n",
       " 'Thermal conductivity': '120 W m<sup>-1</sup> K<sup>-1</sup>',\n",
       " 'Van der waals radius': 'no data',\n",
       " 'Velocity of sound': '5970 m s<sup>-1</sup>',\n",
       " 'Vickers hardness': 'no data MN m<sup>-2</sup>',\n",
       " 'X': 2.2,\n",
       " 'Youngs modulus': '447 GPa',\n",
       " 'Metallic radius': 1.339}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Element(our_atoms[0]).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material to Vector (Make data to predict adsorption energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1 = {'fcc': 0, 'hcp': 1}\n",
    "class2 = {'homo': 0, 'hetero': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(file_name):\n",
    "    atom2vec = pd.read_csv(file_name, index_col=0).transpose()\n",
    "    dataset_str1 = []\n",
    "    dataset_str2 = []\n",
    "    dataset_str3 = []\n",
    "    dataset_str4 = []\n",
    "\n",
    "    for i in range(len(energy_data)):\n",
    "        tmp = energy_data.iloc[i]['material'].split('/')\n",
    "        atom1 = list(atom2vec[tmp[0].split('3')[0]])\n",
    "        atom2 = list(atom2vec[tmp[0].split('3')[1]])\n",
    "        fcc_or_hcp = class1[tmp[1]]\n",
    "        homo_or_hetero = class2[tmp[2]]\n",
    "\n",
    "        input_vec = np.float32(atom1+atom2)\n",
    "        output_energy = np.float32(energy_data.iloc[i]['energy'])\n",
    "\n",
    "        if fcc_or_hcp == 0 and homo_or_hetero == 0:\n",
    "            dataset_str1.append([input_vec, output_energy])\n",
    "        elif fcc_or_hcp == 0 and homo_or_hetero == 1:\n",
    "            dataset_str2.append([input_vec, output_energy])\n",
    "        elif fcc_or_hcp == 1 and homo_or_hetero == 0:\n",
    "            dataset_str3.append([input_vec, output_energy])\n",
    "        else:\n",
    "            dataset_str4.append([input_vec, output_energy])\n",
    "    \n",
    "    return dataset_str1, dataset_str2, dataset_str3, dataset_str4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_str1, dataset_str2, dataset_str3, dataset_str4 = make_dataset('atom2vec_AE20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train/valid/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "# gpu_option\n",
    "gpu_use = 1\n",
    "which_gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(dataset):\n",
    "    torch.manual_seed(0)\n",
    "    train, valid, test = random_split(dataset, [int(len(dataset)*0.8), int(len(dataset)*0.1), int(len(dataset)*0.1)])\n",
    "    \n",
    "    # Data Loader (Input Pipeline)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader1, valid_loader1, test_loader1 = make_loader(dataset_str1)\n",
    "train_loader2, valid_loader2, test_loader2 = make_loader(dataset_str2)\n",
    "train_loader3, valid_loader3, test_loader3 = make_loader(dataset_str3)\n",
    "train_loader4, valid_loader4, test_loader4 = make_loader(dataset_str4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pred_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pred_net, self).__init__()\n",
    "        self.hidden = nn.Linear(64, 10)\n",
    "        self.out = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))\n",
    "        out = self.out(x)\n",
    "        out = out.view(-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50000+1\n",
    "learning_rate = 1e-4\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model,train_loader,valid_loader,criterion,learning_rate,num_epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=1e-6)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        acc = []\n",
    "        train_error = 0\n",
    "        \n",
    "        for i, data in enumerate(train_loader):\n",
    "            atom2vec = data[0].type(torch.FloatTensor).cuda(which_gpu)\n",
    "            real_energy = data[1].type(torch.FloatTensor).cuda(which_gpu)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred_energy = model(atom2vec)\n",
    "            \n",
    "            loss = criterion(pred_energy, real_energy)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_error += loss.item()\n",
    "       \n",
    "        if epoch % 10000 == 0:\n",
    "            avg_train_error = train_error/len(train_loader)\n",
    "            print (\"epoch : [%d/%d], The average loss of train error %.4f\" % (epoch+1, num_epochs, avg_train_error))\n",
    "            eval_loss, output_all, label_all = eval(model, valid_loader, criterion)\n",
    "        \n",
    "def eval(model,valid_loader,criterion):\n",
    "\n",
    "    eval_loss = 0.0\n",
    "    output_all = []\n",
    "    label_all = []\n",
    "\n",
    "    model.eval()\n",
    "    for i, data in enumerate(valid_loader):\n",
    "        atom2vec = data[0].type(torch.FloatTensor).cuda(which_gpu)\n",
    "        real_energy = data[1].type(torch.FloatTensor).cuda(which_gpu)\n",
    "\n",
    "        pred_energy = model(atom2vec)\n",
    "        loss = criterion(pred_energy, real_energy)\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "        output_all.append(pred_energy.data.cpu().numpy())\n",
    "        label_all.append(real_energy.data.cpu().numpy())\n",
    "\n",
    "    avg_loss = eval_loss/len(valid_loader)\n",
    "    print ('The average loss of valid error: {:.4f} \\n'. format(avg_loss))\n",
    "\n",
    "    return avg_loss, output_all, label_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : [1/50001], The average loss of train error 1.6584\n",
      "The average loss of valid error: 2.2451 \n",
      "\n",
      "epoch : [10001/50001], The average loss of train error 0.2204\n",
      "The average loss of valid error: 0.3303 \n",
      "\n",
      "epoch : [20001/50001], The average loss of train error 0.2511\n",
      "The average loss of valid error: 0.3224 \n",
      "\n",
      "epoch : [30001/50001], The average loss of train error 0.1676\n",
      "The average loss of valid error: 0.3362 \n",
      "\n",
      "epoch : [40001/50001], The average loss of train error 0.1320\n",
      "The average loss of valid error: 0.3994 \n",
      "\n",
      "epoch : [50001/50001], The average loss of train error 0.1267\n",
      "The average loss of valid error: 0.4648 \n",
      "\n",
      "--- 304.7345356941223 seconds ---\n",
      "The average loss of valid error: 0.5773 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model1 = pred_net().cuda(which_gpu)\n",
    "# run\n",
    "start_time = time.time()\n",
    "fit(model1,train_loader1,valid_loader1,criterion,learning_rate,num_epochs)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# evaluation\n",
    "avg_loss, pred_all, real_all = eval(model1,test_loader1,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2146153 1.6735339\n"
     ]
    }
   ],
   "source": [
    "pred = list(pred_all[0])\n",
    "real = list(real_all[0])\n",
    "\n",
    "idx = 5\n",
    "print (pred[idx], real[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : [1/50001], The average loss of train error 1.8616\n",
      "The average loss of valid error: 1.7083 \n",
      "\n",
      "epoch : [10001/50001], The average loss of train error 0.1658\n",
      "The average loss of valid error: 0.2958 \n",
      "\n",
      "epoch : [20001/50001], The average loss of train error 0.1228\n",
      "The average loss of valid error: 0.2903 \n",
      "\n",
      "epoch : [30001/50001], The average loss of train error 0.1769\n",
      "The average loss of valid error: 0.3075 \n",
      "\n",
      "epoch : [40001/50001], The average loss of train error 0.1043\n",
      "The average loss of valid error: 0.3112 \n",
      "\n",
      "epoch : [50001/50001], The average loss of train error 0.1219\n",
      "The average loss of valid error: 0.3313 \n",
      "\n",
      "--- 311.1681635379791 seconds ---\n",
      "The average loss of valid error: 0.2306 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model2 = pred_net().cuda(which_gpu)\n",
    "# run\n",
    "start_time = time.time()\n",
    "fit(model2,train_loader2,valid_loader2,criterion,learning_rate,num_epochs)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# evaluation\n",
    "avg_loss, pred_all, real_all = eval(model2,test_loader2,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.702235 2.80992\n"
     ]
    }
   ],
   "source": [
    "pred = list(pred_all[0])\n",
    "real = list(real_all[0])\n",
    "\n",
    "idx = 0\n",
    "print (pred[idx], real[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : [1/50001], The average loss of train error 3.2894\n",
      "The average loss of valid error: 3.8498 \n",
      "\n",
      "epoch : [10001/50001], The average loss of train error 0.1964\n",
      "The average loss of valid error: 0.5860 \n",
      "\n",
      "epoch : [20001/50001], The average loss of train error 0.1539\n",
      "The average loss of valid error: 0.6685 \n",
      "\n",
      "epoch : [30001/50001], The average loss of train error 0.1348\n",
      "The average loss of valid error: 0.7260 \n",
      "\n",
      "epoch : [40001/50001], The average loss of train error 0.1239\n",
      "The average loss of valid error: 0.7640 \n",
      "\n",
      "epoch : [50001/50001], The average loss of train error 0.1542\n",
      "The average loss of valid error: 0.8499 \n",
      "\n",
      "--- 309.71791529655457 seconds ---\n",
      "The average loss of valid error: 0.7631 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model3 = pred_net().cuda(which_gpu)\n",
    "# run\n",
    "start_time = time.time()\n",
    "fit(model3,train_loader3,valid_loader3,criterion,learning_rate,num_epochs)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# evaluation\n",
    "avg_loss, pred_all, real_all = eval(model3,test_loader3,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7012196 2.9374459\n"
     ]
    }
   ],
   "source": [
    "pred = list(pred_all[0])\n",
    "real = list(real_all[0])\n",
    "\n",
    "idx = 0\n",
    "print (pred[idx], real[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : [1/50001], The average loss of train error 2.3100\n",
      "The average loss of valid error: 2.0714 \n",
      "\n",
      "epoch : [10001/50001], The average loss of train error 0.1654\n",
      "The average loss of valid error: 0.1900 \n",
      "\n",
      "epoch : [20001/50001], The average loss of train error 0.1393\n",
      "The average loss of valid error: 0.1483 \n",
      "\n",
      "epoch : [30001/50001], The average loss of train error 0.1064\n",
      "The average loss of valid error: 0.1596 \n",
      "\n",
      "epoch : [40001/50001], The average loss of train error 0.0969\n",
      "The average loss of valid error: 0.1665 \n",
      "\n",
      "epoch : [50001/50001], The average loss of train error 0.1048\n",
      "The average loss of valid error: 0.1812 \n",
      "\n",
      "--- 309.3552613258362 seconds ---\n",
      "The average loss of valid error: 0.3946 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model4 = pred_net().cuda(which_gpu)\n",
    "# run\n",
    "start_time = time.time()\n",
    "fit(model4,train_loader4,valid_loader4,criterion,learning_rate,num_epochs)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# evaluation\n",
    "avg_loss, pred_all, real_all = eval(model4,test_loader4,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9658234 3.03737\n"
     ]
    }
   ],
   "source": [
    "pred = list(pred_all[0])\n",
    "real = list(real_all[0])\n",
    "\n",
    "idx = 0\n",
    "print (pred[idx], real[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
